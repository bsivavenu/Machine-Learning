{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout,Activation\n",
    "from keras.datasets import mnist \n",
    "from keras.optimizers import Adam,SGD,RMSprop\n",
    "from keras.utils import np_utils\n",
    "# from tensorflow.examples.tutorials.mnist import input_data\n",
    "# mnist = input_data.read_data_sets(\"c:/Users/HP/Desktop/mnist/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.lib.npyio.NpzFile'>\n",
      "['x_test', 'x_train', 'y_train', 'y_test']\n"
     ]
    }
   ],
   "source": [
    "f = np.load('d://mnist.npz')\n",
    "print(type(f))\n",
    "print(f.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test (10000, 28, 28) <class 'numpy.ndarray'>\n",
      "x_train (60000, 28, 28) <class 'numpy.ndarray'>\n",
      "y_train (60000,) <class 'numpy.ndarray'>\n",
      "y_test (10000,) <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "for i in f.files:\n",
    "    print(i,f[i].shape,type(f[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, y_train = f['x_train'], f['y_train']\n",
    "x_test, y_test = f['x_test'], f['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000,784)\n",
    "x_test = x_test.reshape(10000,784)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test =  x_test.astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train/255 \n",
    "x_test = x_test/255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000,), (10000,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyCollection at 0xcf08e48>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcdb32b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pcolor(x_train[0].reshape(28,28))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = np_utils.to_categorical(y_test)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  1.  0.  0.]\n",
      " [ 0.  0.  1. ...,  0.  0.  0.]\n",
      " [ 0.  1.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_test[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense,Dropout,Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(128,input_shape = (784,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Activation ('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.Dense at 0xcdb3908>,\n",
       " <keras.layers.core.Activation at 0xd360710>,\n",
       " <keras.layers.core.Dense at 0xcdb3e48>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here in layer one number of parameters are 100480, how this is formed?\n",
    "we have 784 pixels which is 28*28 for a single image and we have defined total 128 neurons so it is 784*128 and since there are 128 neaurons so we will have 128 biases also, so it will be 784*128+128 which is h = wx+b eqaution and 16512 is like 128*128+128 and 1290 is like 128*10+10 where 10 is second Dense layer neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can have any optimizer like adagradient and stoachstic gradient optimizer, i used sgd here,you can try other also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd = SGD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=sgd,loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 2.0044 - val_loss: 1.7172\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 1.5038 - val_loss: 1.2890\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 1.1569 - val_loss: 1.0138\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.9386 - val_loss: 0.8417\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.7995 - val_loss: 0.7288\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.7059 - val_loss: 0.6511\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.6395 - val_loss: 0.5943\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.5903 - val_loss: 0.5516\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.5524 - val_loss: 0.5179\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.5223 - val_loss: 0.4913\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.4979 - val_loss: 0.4692\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.4778 - val_loss: 0.4514\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.4608 - val_loss: 0.4353\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.4463 - val_loss: 0.4224\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.4338 - val_loss: 0.4107\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.4228 - val_loss: 0.4009\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.4132 - val_loss: 0.3923\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.4045 - val_loss: 0.3838\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.3968 - val_loss: 0.3768\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.3899 - val_loss: 0.3707\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.3835 - val_loss: 0.3645\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.3778 - val_loss: 0.3595\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 8s 142us/step - loss: 0.3724 - val_loss: 0.3545\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.3676 - val_loss: 0.3502\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.3631 - val_loss: 0.3458\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.3588 - val_loss: 0.3420\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.3548 - val_loss: 0.3383\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.3512 - val_loss: 0.3351\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.3477 - val_loss: 0.3317\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.3444 - val_loss: 0.3289\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.3414 - val_loss: 0.3260\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.3384 - val_loss: 0.3233\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.3357 - val_loss: 0.3209\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.3330 - val_loss: 0.3182\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.3305 - val_loss: 0.3163\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.3281 - val_loss: 0.3138\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.3258 - val_loss: 0.3117\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.3236 - val_loss: 0.3100\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.3215 - val_loss: 0.3080\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.3194 - val_loss: 0.3062\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.3175 - val_loss: 0.3042\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.3156 - val_loss: 0.3030\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 0.3137 - val_loss: 0.3011\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.3120 - val_loss: 0.2996\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.3103 - val_loss: 0.2982\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.3086 - val_loss: 0.2964\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.3070 - val_loss: 0.2951\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.3054 - val_loss: 0.2937\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 8s 125us/step - loss: 0.3039 - val_loss: 0.2921\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.3024 - val_loss: 0.2912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xbd0efd0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=128,epochs=50,validation_data=(x_test,y_test),verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above process we can lot of things, we set rpoch as 50 so 50 times it will prcoess the samples, how many samples 60000 you can left hand side 60000/60000 and you can see each epoch took how many seconds and loss is how much it differs from actual values that 100-accuracy = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 46us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.29115181632041931"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(x_test,y_test,verbose=1,batch_size=128)\n",
    "score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we passed input values 784 pixels and neurons are 128 in layer1 after softmax activation function the number of weights are 10 which is in dense layer2 as you can see below the required classes are 10 and we have correpsonding weights here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n",
      "128\n",
      "128\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(a)):\n",
    "    print(len(a[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can save model weights and total model also if we want, this helps in reducing the training time again if we want to train in future for same kind of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] weights of MNIST DATA already exists - overwrite? [y/n]n\n"
     ]
    }
   ],
   "source": [
    "model.save_weights('weights of MNIST DATA',overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('model of MNIST DATA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.01095544, -0.04106629, -0.04769368, ..., -0.02254086,\n",
       "          0.08104219, -0.07354458],\n",
       "        [-0.00934229, -0.05220272,  0.04934814, ..., -0.05531628,\n",
       "          0.04720449, -0.01831578],\n",
       "        [-0.03418957, -0.05006023, -0.02254985, ..., -0.05919138,\n",
       "         -0.01812091, -0.07387283],\n",
       "        ..., \n",
       "        [ 0.03372027, -0.06750977,  0.04182287, ..., -0.00528961,\n",
       "          0.006311  ,  0.01676236],\n",
       "        [ 0.04065843,  0.05157644,  0.01355191, ...,  0.05868988,\n",
       "         -0.03920125,  0.00607637],\n",
       "        [-0.05782405, -0.02241317,  0.04209287, ..., -0.02060072,\n",
       "         -0.06434798, -0.01654685]], dtype=float32),\n",
       " array([ 0.02582255, -0.02237135, -0.04541591, -0.01814336,  0.0109027 ,\n",
       "        -0.04642588, -0.0060183 ,  0.01099695, -0.08118869,  0.01063968,\n",
       "        -0.07328641, -0.07488114, -0.01094717,  0.0529811 , -0.0269148 ,\n",
       "        -0.01520439,  0.00910046,  0.00130905, -0.00263578, -0.02850336,\n",
       "         0.04514586,  0.03155594,  0.02753884, -0.0030693 ,  0.01514612,\n",
       "        -0.00217913, -0.0350064 , -0.00149133,  0.00850599,  0.03583829,\n",
       "         0.05633352,  0.03431773, -0.03648329,  0.0801625 ,  0.01749748,\n",
       "         0.08560909, -0.01705959,  0.0180408 , -0.01238572, -0.06510744,\n",
       "         0.03074987,  0.05554528,  0.0292195 , -0.04965381, -0.03133232,\n",
       "        -0.04808248,  0.01664326,  0.03010325,  0.03633954,  0.02225776,\n",
       "        -0.01342003,  0.03664074,  0.00244189, -0.04927839,  0.00057161,\n",
       "         0.01636139, -0.08804242,  0.00036012,  0.05015059,  0.00084328,\n",
       "         0.02612602,  0.05129055,  0.05176839, -0.02737138,  0.00949928,\n",
       "        -0.02790448,  0.04231827, -0.06901716,  0.04183374, -0.01565888,\n",
       "         0.00433888,  0.02622068, -0.00320933,  0.05864296, -0.05826249,\n",
       "         0.04319812,  0.0208949 ,  0.04236165,  0.03646351, -0.03133096,\n",
       "        -0.06483383, -0.07010071,  0.01732203, -0.03392416, -0.0521552 ,\n",
       "         0.00248428, -0.05304619,  0.0142767 , -0.03379935, -0.00851476,\n",
       "        -0.00586104,  0.0844288 , -0.0180548 ,  0.0557082 ,  0.05205275,\n",
       "        -0.04526808,  0.09374934,  0.02899387,  0.00413603, -0.00109593,\n",
       "         0.02914747,  0.06280717, -0.03501156, -0.04118986, -0.00904241,\n",
       "         0.02055963, -0.02979353,  0.05306841, -0.01866691, -0.0168429 ,\n",
       "        -0.02978796,  0.03753828, -0.00135307, -0.07898068,  0.04058775,\n",
       "         0.07605168, -0.00793618,  0.00464317,  0.01801118,  0.03157428,\n",
       "         0.0290626 , -0.01090345, -0.00953088,  0.07625147,  0.0739878 ,\n",
       "         0.03044689,  0.02819601,  0.04313141], dtype=float32),\n",
       " array([[ -5.51656067e-01,   3.57082188e-01,   5.63573003e-01, ...,\n",
       "           4.56250906e-01,  -2.78221071e-01,  -1.69242039e-01],\n",
       "        [  4.94650543e-01,  -3.46524835e-01,   5.21256566e-01, ...,\n",
       "          -1.07765891e-01,   8.34458247e-02,  -7.29215443e-01],\n",
       "        [ -5.33873796e-01,   9.68091935e-02,   6.35105908e-01, ...,\n",
       "           6.77488744e-02,  -2.18517467e-04,   3.53099048e-01],\n",
       "        ..., \n",
       "        [ -3.36527497e-01,   2.95783311e-01,  -3.79088759e-01, ...,\n",
       "           5.00157535e-01,   1.26983881e-01,   2.05490664e-01],\n",
       "        [  2.60010928e-01,  -4.42006290e-01,   2.22037569e-01, ...,\n",
       "          -3.97502244e-01,  -4.24237609e-01,   1.41398787e-01],\n",
       "        [ -4.44899201e-01,  -3.47436853e-02,  -3.34874153e-01, ...,\n",
       "           3.89970727e-02,  -3.56132269e-01,  -1.54121742e-01]], dtype=float32),\n",
       " array([-0.00013928,  0.02980616,  0.0278994 ,  0.02368832, -0.04167518,\n",
       "         0.05838185, -0.01847737, -0.00242549, -0.02663427, -0.05042362], dtype=float32)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.get_weights()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.get_weights()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.get_weights()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.get_weights()[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can predict the classes for a given data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 106us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(x_test,batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can estimate / predict what is the probablity of a class for a given data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 89us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  1.07453801e-04,   1.11053635e-06,   1.62034223e-04, ...,\n",
       "          9.96168911e-01,   2.28766203e-05,   1.77923043e-03],\n",
       "       [  1.93929132e-02,   6.52925286e-04,   7.93924570e-01, ...,\n",
       "          7.34169760e-07,   7.48457946e-03,   3.22276219e-06],\n",
       "       [  1.47521578e-05,   9.71576035e-01,   1.07778888e-02, ...,\n",
       "          5.07422863e-03,   2.97996565e-03,   9.36807774e-04],\n",
       "       ..., \n",
       "       [  3.14539307e-06,   3.42625499e-05,   7.04521954e-05, ...,\n",
       "          2.59239832e-03,   1.19983312e-02,   3.93913016e-02],\n",
       "       [  3.17703583e-03,   3.72383650e-03,   8.26828182e-04, ...,\n",
       "          2.93844147e-04,   3.75050485e-01,   4.91985178e-04],\n",
       "       [  4.12568537e-04,   1.98531325e-07,   1.27972185e-03, ...,\n",
       "          1.15531819e-07,   9.73709939e-06,   2.58465298e-06]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
