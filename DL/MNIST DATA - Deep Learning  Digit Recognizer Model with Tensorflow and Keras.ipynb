{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout,Activation\n",
    "from keras.datasets import mnist \n",
    "from keras.optimizers import Adam,SGD,RMSprop\n",
    "from keras.utils import np_utils\n",
    "# from tensorflow.examples.tutorials.mnist import input_data\n",
    "# mnist = input_data.read_data_sets(\"c:/Users/HP/Desktop/mnist/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.lib.npyio.NpzFile'>\n",
      "['x_test', 'x_train', 'y_train', 'y_test']\n"
     ]
    }
   ],
   "source": [
    "f = np.load('d://mnist.npz')\n",
    "print(type(f))\n",
    "print(f.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test (10000, 28, 28) <class 'numpy.ndarray'>\n",
      "x_train (60000, 28, 28) <class 'numpy.ndarray'>\n",
      "y_train (60000,) <class 'numpy.ndarray'>\n",
      "y_test (10000,) <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "for i in f.files:\n",
    "    print(i,f[i].shape,type(f[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, y_train = f['x_train'], f['y_train']\n",
    "x_test, y_test = f['x_test'], f['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000,784)\n",
    "x_test = x_test.reshape(10000,784)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test =  x_test.astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train/255 \n",
    "x_test = x_test/255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000,), (10000,))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyCollection at 0xdf89a90>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xda99eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pcolor(x_train[0].reshape(28,28))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = np_utils.to_categorical(y_test)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  1.  0.  0.]\n",
      " [ 0.  0.  1. ...,  0.  0.  0.]\n",
      " [ 0.  1.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_test[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense,Dropout,Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(128,input_shape = (784,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Activation ('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.Dense at 0xdf6f9e8>,\n",
       " <keras.layers.core.Activation at 0xdffa1d0>,\n",
       " <keras.layers.core.Dense at 0xe012a20>]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here in layer one number of parameters are 100480, how this is formed?\n",
    "we have 784 pixels which is 28*28 for a single image and we have defined total 128 neurons so it is 784*128 and since there are 128 neaurons so we will have 128 biases also, so it will be 784*128+128 which is h = wx+b eqaution and 16512 is like 128*128+128 and 1290 is like 128*10+10 where 10 is second Dense layer neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can have any optimizer like adagradient and stoachstic gradient optimizer, i used sgd here,you can try other also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd = SGD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=sgd,loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 2.0191 - val_loss: 1.7331\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 1.5207 - val_loss: 1.3016\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 1.1691 - val_loss: 1.0189\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.9459 - val_loss: 0.8437\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.8054 - val_loss: 0.7316\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.7122 - val_loss: 0.6541\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.6463 - val_loss: 0.5990\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.5973 - val_loss: 0.5561\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.5595 - val_loss: 0.5228\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.5295 - val_loss: 0.4959\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.5048 - val_loss: 0.4739\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.4843 - val_loss: 0.4555\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.4669 - val_loss: 0.4399\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.4520 - val_loss: 0.4261\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.4391 - val_loss: 0.4143\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.4278 - val_loss: 0.4040\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.4178 - val_loss: 0.3947\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.4089 - val_loss: 0.3864\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.4008 - val_loss: 0.3795\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.3936 - val_loss: 0.3728\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.3871 - val_loss: 0.3669\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.3811 - val_loss: 0.3613\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.3756 - val_loss: 0.3561\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.3705 - val_loss: 0.3516\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 7s 125us/step - loss: 0.3658 - val_loss: 0.3473\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.3614 - val_loss: 0.3437\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.3574 - val_loss: 0.3397\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.3535 - val_loss: 0.3366\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.3500 - val_loss: 0.3330\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.3466 - val_loss: 0.3298\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 0.3434 - val_loss: 0.3271\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.3403 - val_loss: 0.3241\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.3375 - val_loss: 0.3219\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.3347 - val_loss: 0.3195\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.3321 - val_loss: 0.3170\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 4s 75us/step - loss: 0.3296 - val_loss: 0.3146\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.3272 - val_loss: 0.3126\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 7s 125us/step - loss: 0.3249 - val_loss: 0.3106\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.3227 - val_loss: 0.3085\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.3206 - val_loss: 0.3067\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.3185 - val_loss: 0.3049\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.3166 - val_loss: 0.3031\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.3147 - val_loss: 0.3015\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 7s 125us/step - loss: 0.3129 - val_loss: 0.3000\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.3111 - val_loss: 0.2981\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.3094 - val_loss: 0.2966\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.3077 - val_loss: 0.2955\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 8s 125us/step - loss: 0.3060 - val_loss: 0.2942\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.3045 - val_loss: 0.2924\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.3029 - val_loss: 0.2911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xe0a7cc0>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=128,epochs=50,validation_data=(x_test,y_test),verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above process we can lot of things, we set rpoch as 50 so 50 times it will prcoess the samples, how many samples 60000 you can left hand side 60000/60000 and you can see each epoch took how many seconds and loss is how much it differs from actual values that 100-accuracy = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 55us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.29105164546966555"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(x_test,y_test,verbose=1,batch_size=128)\n",
    "score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we passed input values 784 pixels and neurons are 128 in layer1 after softmax activation function the number of weights are 10 which is in dense layer2 as you can see below the required classes are 10 and we have correpsonding weights here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n",
      "128\n",
      "128\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(a)):\n",
    "    print(len(a[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can save model weights and total model also if we want, this helps in reducing the training time again if we want to train in future for same kind of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('weights of MNIST DATA',overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('model of MNIST DATA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.07187185,  0.02504828, -0.02580512, ..., -0.06244579,\n",
       "          0.04792901, -0.00420871],\n",
       "        [-0.06260266,  0.01043976, -0.00557225, ..., -0.01969498,\n",
       "          0.03803308, -0.06575457],\n",
       "        [ 0.00588904,  0.02466631, -0.06622163, ...,  0.04434753,\n",
       "          0.03004362, -0.048332  ],\n",
       "        ..., \n",
       "        [-0.04106047,  0.07349361,  0.06090853, ..., -0.06694173,\n",
       "         -0.02262502, -0.01557706],\n",
       "        [-0.01618533, -0.05091154,  0.06166292, ..., -0.04471367,\n",
       "         -0.0327216 , -0.00018435],\n",
       "        [-0.05473518,  0.01410709,  0.04872536, ..., -0.06675633,\n",
       "         -0.04530768,  0.07044797]], dtype=float32),\n",
       " array([ 0.04504199,  0.04218989,  0.01774321, -0.01982485, -0.02112029,\n",
       "         0.02706102,  0.02476061,  0.01740664, -0.03740566, -0.02151075,\n",
       "         0.03074829,  0.00277257, -0.00740327, -0.02381265,  0.04895231,\n",
       "         0.04223849,  0.04579436,  0.08561426, -0.04604056,  0.02170798,\n",
       "        -0.04918344,  0.04772649,  0.05187794,  0.0220109 , -0.03994944,\n",
       "        -0.02293861,  0.05036098, -0.03231714,  0.05415414,  0.02370826,\n",
       "        -0.00453782,  0.06609771, -0.01778715,  0.03259639, -0.01720873,\n",
       "        -0.00947946, -0.0237804 , -0.01834289,  0.03966389,  0.01951062,\n",
       "         0.00600143,  0.01988098, -0.01551944, -0.04164936, -0.05280154,\n",
       "        -0.01989751,  0.00813855,  0.00714553, -0.0032514 ,  0.11651427,\n",
       "         0.00207678, -0.00883657, -0.00610114,  0.03268597,  0.02652838,\n",
       "        -0.05845313,  0.08420219,  0.05588787,  0.05400625,  0.03066044,\n",
       "        -0.0441858 ,  0.07836421, -0.01821784, -0.01171356,  0.01270633,\n",
       "        -0.00503745,  0.08555702, -0.01944429, -0.04942964, -0.01256825,\n",
       "         0.0112891 ,  0.05697313,  0.05918407,  0.01075232,  0.0211738 ,\n",
       "        -0.03563059, -0.03692529, -0.02608944,  0.04673638, -0.00284945,\n",
       "         0.11191449,  0.09099099, -0.01995904, -0.04956148, -0.05712105,\n",
       "        -0.00795192,  0.00999161,  0.02763253, -0.0563509 , -0.0301649 ,\n",
       "         0.03656791, -0.04775389, -0.08467728,  0.02306549,  0.02304221,\n",
       "         0.02483566,  0.05993073, -0.06516051,  0.05653978, -0.01988524,\n",
       "         0.03971592,  0.01410878, -0.0195488 , -0.07918223,  0.05035705,\n",
       "         0.02188132,  0.05596082, -0.01982723, -0.02618467,  0.01771397,\n",
       "         0.0488576 , -0.04928318, -0.01331383,  0.11351611, -0.04939042,\n",
       "         0.04903161, -0.06621884, -0.0831889 , -0.02646668,  0.03532671,\n",
       "         0.00967536,  0.02827988,  0.0058779 , -0.0149812 , -0.02507853,\n",
       "        -0.05045465, -0.00264048,  0.02773419], dtype=float32),\n",
       " array([[-0.57564157,  0.51052719,  0.27914596, ...,  0.18650945,\n",
       "         -0.31673819,  0.28511411],\n",
       "        [-0.12050758,  0.49908954, -0.28485915, ...,  0.33229035,\n",
       "          0.33810502, -0.35495451],\n",
       "        [ 0.17089801,  0.09571644, -0.08931844, ..., -0.5077126 ,\n",
       "         -0.23222378, -0.04462751],\n",
       "        ..., \n",
       "        [ 0.49249497, -0.33135459,  0.48022482, ...,  0.4224788 ,\n",
       "         -0.04880672,  0.10664975],\n",
       "        [ 0.23321511, -0.20661771, -0.00828364, ...,  0.07182698,\n",
       "         -0.02371741,  0.33783296],\n",
       "        [ 0.4263536 , -0.02183532,  0.15642974, ...,  0.42881361,\n",
       "         -0.3599672 , -0.02361666]], dtype=float32),\n",
       " array([-0.03088828, -0.02608039,  0.00451861,  0.02426156,  0.00177456,\n",
       "         0.06850287, -0.03433947,  0.01909995, -0.02470453, -0.00214456], dtype=float32)]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.get_weights()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.get_weights()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.get_weights()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.get_weights()[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can predict the classes for a given data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 88us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(x_test,batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can estimate / predict what is the probablity of a class for a given data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 90us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  1.35248163e-04,   1.13898193e-06,   1.65736696e-04, ...,\n",
       "          9.96418118e-01,   2.97627139e-05,   1.98001671e-03],\n",
       "       [  1.39817549e-02,   3.82891711e-04,   9.05116141e-01, ...,\n",
       "          2.39879796e-06,   3.94000765e-03,   2.37491986e-06],\n",
       "       [  8.55008693e-06,   9.73747969e-01,   9.22370981e-03, ...,\n",
       "          5.80060715e-03,   2.83394894e-03,   8.36666615e-04],\n",
       "       ..., \n",
       "       [  2.80401741e-06,   4.79741502e-05,   8.00588969e-05, ...,\n",
       "          2.36340379e-03,   1.13057271e-02,   4.78667803e-02],\n",
       "       [  3.22640082e-03,   3.82505311e-03,   4.83676820e-04, ...,\n",
       "          3.71241185e-04,   3.46038967e-01,   4.83471813e-04],\n",
       "       [  4.58915165e-04,   3.26710989e-07,   1.25062047e-03, ...,\n",
       "          1.60107092e-07,   2.04196222e-05,   2.38955636e-06]], dtype=float32)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
